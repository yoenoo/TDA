{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "759ceaa1-203d-4253-b91f-91fcbeeb6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d5886409-e1cd-4bd2-850c-c4a9930d3ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mnist_train = datasets.MNIST(root=\"./data\", train=True, \n",
    "                             download=True, transform=transform)\n",
    "images, labels = mnist_train.data, mnist_train.targets\n",
    "\n",
    "labels_idx = torch.where(torch.isin(labels, torch.tensor([1,7])))\n",
    "images = images[labels_idx] / 255.\n",
    "labels = labels[labels_idx]\n",
    "\n",
    "ds = TensorDataset(images, labels)\n",
    "train_loader = DataLoader(ds, batch_size=bs)\n",
    "\n",
    "# mnist_test = datasets.MNIST(root=\"./data\", train=False, \n",
    "#                             download=True, transform=transform)\n",
    "# test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2abf9413-6856-4fd4-8bd7-1ef5293e7308",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ff4971f7-6db7-4b04-8c6a-153d9be773a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "70125b1e-4f5f-4107-958a-73194dcba820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, f_in, f_out):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(f_in, f_out)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "f73aeb1c-b498-4cb9-bbe1-7cb984b236f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(28*28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "6b21d157-9bd7-4dff-8790-28b99ba022fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.006711006164550781,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 25,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 50,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb601209ec354dd5b00bbf14b608034d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = SGD(model.parameters(), lr=1e-3)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "model.train()\n",
    "for epoch in (pbar := trange(epochs)):\n",
    "    batch_losses = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        data = data.reshape(-1, 28*28)\n",
    "        target = torch.where(target == 7, 1., 0.).reshape(-1,1)\n",
    "        output = model(data)\n",
    "        \n",
    "        loss = F.binary_cross_entropy(output, target)\n",
    "        # loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # output = model(data.reshape(-1,28*28))\n",
    "        # target_preds = torch.where(output < 0.5, 1, 7).reshape(-1)\n",
    "        # acc = (target == target_preds).sum() / len(output)\n",
    "        \n",
    "        batch_losses.append(loss.item())\n",
    "        \n",
    "    epoch_loss = np.mean(batch_losses)\n",
    "    pbar.set_description(f\"Epoch: {epoch}, Average loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "0518f837-59bb-485d-87c6-7d616bed110b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (fc): Linear(in_features=784, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "22c0ab46-ccc4-4171-af94-da07ecd7c3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_model_functional = False\n",
    "\n",
    "def _set_attr(obj, names, val):\n",
    "    if len(names) == 1:\n",
    "        setattr(obj, names[0], val)\n",
    "    else:\n",
    "        _set_attr(getattr(obj, names[0]), names[1:], val)\n",
    "\n",
    "def _del_attr(obj, names):\n",
    "    if len(names) == 1:\n",
    "        delattr(obj, names[0])\n",
    "    else:\n",
    "        _del_attr(getattr(obj, names[0]), names[1:])\n",
    "        \n",
    "def _param_names(model):\n",
    "    param_names = tuple(name for name, _ in _model_params(model))\n",
    "    return param_names\n",
    "    \n",
    "def _param_shapes(model):\n",
    "    param_shapes = tuple(p.shape for _, p in _model_params(model))\n",
    "    return param_shapes\n",
    "\n",
    "def _model_params(model, with_names=True):\n",
    "    assert not is_model_functional\n",
    "    return tuple((name, p) if with_names else p for name, p in model.named_parameters() if p.requires_grad)\n",
    "\n",
    "def _model_make_functional(model):\n",
    "    assert not is_model_functional\n",
    "    params = tuple(p.detach().requires_grad_() for p in _model_params(model, False))\n",
    "    \n",
    "    for name in model._param_names:\n",
    "        # print(\"_del_attr\", name.split(\".\"))\n",
    "        _del_attr(model, name.split(\".\"))\n",
    "    \n",
    "    if_model_functional = True\n",
    "    return params\n",
    "    \n",
    "def _flatten_params_like(params_like):\n",
    "    vec = []\n",
    "    for p in params_like:\n",
    "        vec.append(p.view(-1))\n",
    "    return torch.cat(vec)\n",
    "\n",
    "def _reshape_like_params(vec):\n",
    "    pointer = 0\n",
    "    split_tensors = []\n",
    "    for dim in model._param_shapes:\n",
    "        num_param = dim.numel()\n",
    "        split_tensors.append(vec[pointer:pointer+num_param].view(dim))\n",
    "        pointer += num_param\n",
    "    return tuple(split_tensors)\n",
    "\n",
    "def _model_reinsert_params(model, params, register=False):\n",
    "    for name, p in zip(model._param_names, params):\n",
    "        # print(\"_set_attr\", name.split(\".\"))\n",
    "        _set_attr(model, name.split(\".\"), torch.nn.Parameter(p) if register else p)\n",
    "        \n",
    "    is_model_functional = not register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "fdcb1c21-7f64-4220-9559-a476f0906223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = _model_make_functional(model)\n",
    "# flat_params = _flatten_params_like(params)\n",
    "\n",
    "# _model_reinsert_params(model, _reshape_like_params(flat_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "162b5c1a-16a7-4732-9cec-6eaa0b00a197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hessian min eigval 0.20000000298023224\n",
      "hessian max eigval 123.18155670166016\n"
     ]
    }
   ],
   "source": [
    "# after training...\n",
    "model._param_shapes = _param_shapes(model)\n",
    "model._param_names = _param_names(model)\n",
    "\n",
    "params = _model_make_functional(model)\n",
    "flat_params = _flatten_params_like(params)\n",
    "\n",
    "d = flat_params.shape[0]\n",
    "damp = 0.2\n",
    "hess = 0\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    \n",
    "    def f(theta_):\n",
    "        _model_reinsert_params(model, _reshape_like_params(theta_))\n",
    "        output = model(data.reshape(-1, 28*28))\n",
    "        # target = torch.where(target == 7, 1., 0.).reshape(-1,1)\n",
    "\n",
    "        loss = F.binary_cross_entropy(output, torch.where(target == 7, 1., 0.).reshape(-1,1))\n",
    "        return loss\n",
    "    \n",
    "    hess_batch = torch.autograd.functional.hessian(f, flat_params).detach()\n",
    "    hess += hess_batch * len(data)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    _model_reinsert_params(model, _reshape_like_params(flat_params), register=True)\n",
    "    hess /= len(train_loader)\n",
    "    hess += damp * torch.eye(d) # TODO: why do we need this?\n",
    "    \n",
    "    check_eigvals = True\n",
    "    if check_eigvals:\n",
    "        eigvals = np.linalg.eigvalsh(hess.cpu().numpy())\n",
    "        print(f\"hessian min eigval {np.min(eigvals).item()}\")\n",
    "        print(f\"hessian max eigval {np.max(eigvals).item()}\")\n",
    "        if not np.all(eigvals >= 0):\n",
    "            raise ValueError()\n",
    "            \n",
    "    inverse_hess = torch.inverse(hess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "4014f4ea-3cdc-4ed6-82c4-abb66f2415b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 5.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 5.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 5.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 5.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 2.3519]])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "e5e297c5-e1d4-4557-8b79-a028166ea7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=1, bias=True)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "d4bef9cc-b4a5-4b7b-a7f6-40d2a965c549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _loss_grad_loader_wrapper(model):\n",
    "    # assume train_loss = test_loss\n",
    "    params = _model_params(model)\n",
    "    print(params)\n",
    "    flat_params = _flatten_params_like(params)\n",
    "    return flat_params\n",
    "\n",
    "# def _loss_grad(idxs):\n",
    "#     grad = 0\n",
    "#     for grad_batch, batch_size\n",
    "#         grad += grad_batch * batch_size\n",
    "#     return grad / len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "365031e1-3a33-432e-9e3b-ba6aad4fe50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('fc.weight', Parameter containing:\n",
      "tensor([[-1.5153e-02, -2.9503e-02,  2.3125e-02, -2.8672e-02,  2.9786e-02,\n",
      "          1.5562e-02,  3.3335e-02,  2.3777e-03, -3.5537e-02, -2.0688e-02,\n",
      "         -2.7439e-02, -1.5559e-02, -1.8334e-02, -2.7009e-03, -1.8452e-02,\n",
      "          1.4241e-02,  2.0550e-02, -1.4958e-02, -2.9243e-02,  1.8480e-03,\n",
      "         -1.8899e-02,  3.4272e-02,  2.0476e-02, -8.5623e-03,  3.5247e-02,\n",
      "          1.4442e-02,  5.1014e-03,  1.4080e-02, -2.5379e-02, -2.9842e-03,\n",
      "          4.2720e-03,  1.4757e-03, -6.0699e-03, -2.7218e-02,  2.9360e-02,\n",
      "          1.9579e-02,  2.1962e-02, -5.8839e-03, -6.1890e-04, -3.5157e-03,\n",
      "         -1.2685e-03, -2.3056e-02, -3.5493e-03, -1.6992e-03,  6.7121e-03,\n",
      "         -2.0090e-02, -3.0533e-02,  1.2062e-02, -8.5477e-03,  4.0748e-03,\n",
      "         -7.1618e-03,  2.7513e-02,  2.1717e-02, -1.7721e-02,  2.4279e-02,\n",
      "         -3.2521e-02, -1.7433e-02,  2.2365e-02,  1.9440e-02, -2.6831e-02,\n",
      "         -2.5402e-03, -3.0336e-02,  2.1283e-02, -2.6553e-02,  2.7480e-02,\n",
      "         -2.5954e-02,  2.7707e-02,  2.5805e-02,  8.2833e-03,  2.0793e-02,\n",
      "          7.4405e-03,  2.4854e-03, -2.0859e-02,  6.7422e-03,  1.8777e-02,\n",
      "          2.0076e-02,  2.9233e-02, -2.9971e-02,  2.8480e-03,  1.8178e-02,\n",
      "         -1.4432e-02,  1.1525e-02,  7.2792e-03,  2.9347e-03,  1.2064e-02,\n",
      "         -2.8568e-02,  2.7258e-02, -7.7804e-03, -1.2836e-02,  1.7049e-02,\n",
      "          7.2455e-03,  2.4716e-02, -1.7443e-02, -1.0888e-02, -3.4669e-02,\n",
      "          3.7978e-03, -1.0213e-02, -2.2688e-02, -2.8936e-02,  1.1044e-02,\n",
      "         -1.5379e-02, -2.3138e-02, -2.5785e-02, -3.5908e-02,  3.1229e-02,\n",
      "         -1.8524e-02, -2.4724e-02, -2.5683e-03, -3.0845e-02,  8.4719e-03,\n",
      "         -2.5205e-02, -2.0476e-03, -3.3433e-02,  1.0195e-02, -2.3353e-02,\n",
      "          3.3693e-02, -1.1789e-03,  1.0085e-02, -5.9266e-03,  1.8591e-02,\n",
      "         -1.3545e-02,  1.5204e-02, -2.6741e-02, -4.1202e-02, -4.0653e-02,\n",
      "         -6.8787e-02, -5.9998e-02, -6.7031e-02, -5.0193e-02, -3.3937e-02,\n",
      "         -4.4195e-02, -5.3350e-02, -1.7360e-02, -4.4574e-02, -1.5232e-02,\n",
      "         -3.7331e-02, -3.6339e-02,  1.5053e-02, -3.1646e-02, -1.1075e-02,\n",
      "         -2.0321e-02, -2.5491e-02, -3.2236e-02, -3.5172e-03, -5.3734e-03,\n",
      "         -3.2084e-02,  2.8223e-02, -1.6043e-02, -7.4185e-03,  2.9899e-02,\n",
      "         -3.6216e-02, -4.7856e-02, -3.1330e-02, -1.2696e-01, -1.4789e-01,\n",
      "         -1.6208e-01, -1.0756e-01, -1.0720e-01, -1.1378e-01, -9.7946e-02,\n",
      "         -5.9338e-02, -6.8310e-02,  3.3851e-03,  2.7142e-03, -2.4720e-02,\n",
      "          5.0986e-03, -1.8392e-02, -3.4530e-02, -1.5843e-02, -2.4442e-02,\n",
      "          9.8419e-03, -3.5404e-02, -3.4156e-05,  3.0359e-02,  2.8248e-02,\n",
      "          3.4007e-02,  7.8644e-03,  4.7007e-02,  7.1888e-02,  5.5948e-02,\n",
      "         -8.5602e-03, -3.3031e-02, -8.7503e-02, -5.4196e-02, -6.8663e-02,\n",
      "         -1.0427e-01, -6.5373e-02, -4.6828e-02, -2.6865e-02, -7.0076e-02,\n",
      "          1.6332e-02, -5.8802e-04,  2.3257e-02,  3.7473e-04,  1.1257e-02,\n",
      "          1.1772e-02, -3.5031e-02, -5.5044e-04, -2.2028e-02, -3.4717e-04,\n",
      "          2.1350e-02,  1.7075e-02,  4.4916e-02,  3.4640e-02,  8.7442e-02,\n",
      "          1.2376e-01,  1.5983e-01,  1.3833e-01,  1.0345e-01,  8.2285e-02,\n",
      "          1.3649e-02, -1.0123e-02,  1.5633e-02,  2.3643e-02,  2.4994e-02,\n",
      "         -2.0359e-02, -1.2239e-02,  3.4013e-02, -2.7649e-02,  3.0546e-02,\n",
      "          4.8872e-03, -1.6811e-02,  2.5787e-02,  2.9105e-03,  1.2440e-02,\n",
      "          5.7873e-03, -3.7458e-03,  2.5569e-02,  2.0817e-02, -1.8219e-03,\n",
      "          5.0268e-02,  1.0700e-01,  1.1123e-01,  1.9191e-01,  1.6724e-01,\n",
      "          1.8103e-01,  1.9373e-01,  9.0034e-02,  9.7075e-02,  8.4695e-02,\n",
      "          9.0133e-02,  1.0889e-01,  1.0302e-01,  5.4372e-02,  3.3903e-02,\n",
      "          3.9855e-03,  2.0926e-02,  1.3329e-02, -3.3596e-03,  3.3810e-02,\n",
      "          1.1302e-02,  1.3759e-02, -2.6026e-02, -2.9103e-04, -2.5660e-02,\n",
      "          2.1560e-02, -4.8334e-04,  8.3695e-03,  3.5473e-02,  8.4918e-02,\n",
      "          1.3504e-01,  1.4666e-01,  1.8287e-01,  1.7415e-01,  1.3265e-01,\n",
      "          5.6191e-02, -2.0879e-02, -2.6681e-02,  5.4173e-02,  1.0090e-01,\n",
      "          8.7153e-02,  1.3301e-01,  1.1659e-01,  8.4534e-02,  5.8471e-02,\n",
      "          4.2269e-02, -3.0454e-02,  5.3054e-03,  2.5611e-02, -1.6840e-02,\n",
      "          2.8934e-02, -2.6133e-02,  2.4027e-02,  7.6943e-03,  3.6414e-02,\n",
      "          7.0358e-02,  7.3971e-02,  9.1210e-02,  9.1428e-02,  1.2621e-01,\n",
      "          1.4222e-01,  1.1956e-01,  8.7955e-02, -3.7883e-02, -1.4197e-01,\n",
      "         -1.1236e-01,  2.9263e-02,  9.8395e-02,  1.3196e-01,  1.6031e-01,\n",
      "          1.2201e-01,  8.1031e-02,  1.0730e-02,  4.3320e-02, -2.8420e-02,\n",
      "          1.5887e-03,  3.5516e-02,  3.4346e-03, -2.7280e-02, -1.5014e-02,\n",
      "          2.9261e-02, -1.8529e-03,  1.8571e-02,  6.2083e-02,  1.6145e-02,\n",
      "          3.9237e-02,  6.3825e-02,  8.5409e-02,  8.4527e-02,  6.8344e-02,\n",
      "         -8.5656e-03, -1.1880e-01, -2.6325e-01, -2.0881e-01, -1.2383e-03,\n",
      "          1.4550e-01,  1.4352e-01,  1.3657e-01,  5.1804e-02,  3.0807e-02,\n",
      "          6.6190e-03,  1.0326e-02,  8.2910e-03,  1.1155e-02, -1.7860e-02,\n",
      "         -2.3856e-02,  7.4472e-03, -5.1056e-03,  3.4077e-02,  1.4631e-02,\n",
      "          1.3263e-02,  2.4789e-03,  6.3254e-02,  6.9780e-02,  5.1273e-02,\n",
      "          5.9819e-02,  7.7313e-02,  1.2484e-02, -3.4473e-03, -1.5296e-01,\n",
      "         -2.7986e-01, -2.3101e-01, -1.0688e-02,  1.7866e-01,  1.8908e-01,\n",
      "          1.1743e-01,  7.4746e-02,  4.1966e-02, -4.0203e-03, -1.5730e-02,\n",
      "          1.8167e-02, -2.8160e-02,  4.1268e-03,  1.0576e-02,  8.2862e-03,\n",
      "         -2.1755e-02,  1.7867e-02, -1.9125e-03, -7.9788e-03,  5.0574e-02,\n",
      "          1.6149e-02,  3.6229e-02,  7.0272e-02,  4.9464e-02,  4.1787e-02,\n",
      "          4.3203e-02, -3.2473e-02, -2.6331e-01, -3.2995e-01, -1.6416e-01,\n",
      "          8.0289e-02,  1.4971e-01,  1.8815e-01,  1.3486e-01,  3.9580e-02,\n",
      "          2.3400e-02,  4.3718e-03, -2.1220e-02,  1.5055e-02,  2.5196e-02,\n",
      "          7.9492e-03, -2.4598e-02, -2.2723e-02,  2.8689e-02, -1.7923e-02,\n",
      "         -2.9826e-02,  1.0688e-02,  2.2138e-02,  1.3477e-02,  2.2158e-02,\n",
      "          5.8566e-02,  4.1357e-02,  2.0583e-02,  3.8169e-02, -7.2258e-02,\n",
      "         -2.8014e-01, -3.1643e-01, -1.2593e-01,  1.0849e-01,  1.9582e-01,\n",
      "          1.6711e-01,  1.3425e-01,  6.5543e-02,  8.1158e-03,  5.1095e-02,\n",
      "          2.9917e-02,  1.0038e-02, -3.6114e-03, -1.6096e-02,  1.9936e-02,\n",
      "         -1.6783e-02,  1.2516e-02,  1.2452e-02,  1.6675e-02, -2.8733e-02,\n",
      "         -1.8821e-02,  2.1745e-02,  3.4790e-02,  9.1708e-03,  4.0643e-02,\n",
      "         -1.2139e-04,  6.2980e-04, -7.1326e-02, -2.2111e-01, -2.0337e-01,\n",
      "         -3.0990e-02,  1.8904e-01,  2.2565e-01,  1.2155e-01,  8.3217e-02,\n",
      "          6.7314e-02,  1.5409e-02,  3.5401e-02, -1.2901e-02,  3.3786e-03,\n",
      "          1.7307e-02, -1.8378e-02,  3.3187e-02,  2.4272e-02,  2.4655e-02,\n",
      "         -6.8849e-03, -1.5477e-02,  2.5860e-02,  6.5329e-03, -1.0033e-02,\n",
      "          3.3746e-02,  1.7723e-02,  6.7687e-02,  2.8662e-04, -1.2891e-02,\n",
      "         -1.3663e-01, -1.7307e-01, -1.2162e-01,  3.2718e-02,  1.7316e-01,\n",
      "          1.4526e-01,  9.9546e-02,  7.1392e-02,  5.6189e-02,  5.5549e-02,\n",
      "          4.5118e-02, -1.8330e-02,  3.3185e-02,  8.1875e-03,  4.4077e-03,\n",
      "         -3.2205e-03,  9.8936e-03, -2.1582e-02, -1.4954e-02,  1.3058e-02,\n",
      "          1.2885e-02, -3.1168e-02, -9.0053e-03,  4.2324e-02,  4.8636e-02,\n",
      "          1.9721e-02,  4.1621e-04, -3.0320e-02, -8.0884e-02, -1.2312e-01,\n",
      "         -6.2080e-02,  3.9337e-02,  1.1274e-01,  7.3948e-02,  1.0465e-01,\n",
      "          6.0276e-02,  5.6616e-02,  1.5999e-02,  1.5174e-02,  3.0856e-03,\n",
      "         -2.6845e-02,  3.4020e-02, -2.3334e-02,  7.3919e-03,  1.8022e-02,\n",
      "          3.2666e-02, -1.7566e-02,  1.4404e-02,  3.3926e-03,  1.6298e-02,\n",
      "          2.1132e-02,  1.5534e-02, -2.1016e-02, -2.2843e-02, -2.1582e-02,\n",
      "         -7.4282e-02, -8.1784e-02, -5.4737e-02, -4.2066e-02,  6.7306e-02,\n",
      "          5.0127e-02,  5.8316e-02,  6.8979e-02,  3.0107e-02,  3.4390e-02,\n",
      "         -1.5050e-02, -3.4616e-03,  3.4653e-02, -9.7022e-03,  1.1222e-02,\n",
      "         -2.3028e-02,  7.5394e-03, -2.8224e-03,  2.7735e-02,  2.6438e-02,\n",
      "         -1.8518e-02, -8.4034e-03,  1.1649e-02,  8.9161e-03, -4.5032e-02,\n",
      "          8.7404e-03, -2.7389e-02, -7.9653e-02, -7.5169e-02, -3.1878e-02,\n",
      "         -3.8097e-02, -3.9928e-02, -1.3178e-02,  2.6139e-02,  4.8567e-02,\n",
      "          2.7045e-02, -1.0510e-02, -3.4272e-02,  1.0233e-03,  2.9096e-02,\n",
      "          9.2875e-03, -3.5857e-02, -1.7740e-02,  1.1251e-02, -2.8342e-02,\n",
      "          2.4659e-02, -2.8481e-02, -2.4712e-02, -1.9515e-02,  6.4829e-03,\n",
      "          2.7513e-04, -4.4913e-02, -3.2936e-02, -5.8546e-02, -4.2021e-02,\n",
      "         -5.4387e-02, -9.7626e-02, -1.3108e-02, -2.2733e-02, -2.5738e-02,\n",
      "         -2.6397e-02, -3.4321e-02,  8.9553e-03,  4.2027e-03, -1.2860e-02,\n",
      "         -8.9620e-03,  2.4108e-02, -6.4886e-03,  4.6848e-03, -1.9119e-02,\n",
      "          3.3681e-02, -1.9343e-02,  4.1137e-04,  1.0784e-02,  3.6224e-03,\n",
      "          3.5608e-02, -1.4210e-02, -3.6243e-02, -4.2428e-02, -2.3409e-02,\n",
      "         -6.5867e-02, -8.1299e-02, -4.1568e-02, -7.0486e-02, -4.2664e-02,\n",
      "         -1.6807e-02,  7.4527e-03, -3.4600e-02, -7.7287e-02, -6.6462e-02,\n",
      "         -4.4852e-02, -1.8775e-02,  1.2597e-02,  1.7576e-03, -2.1390e-02,\n",
      "         -2.3525e-02, -3.9021e-03,  2.2244e-02, -7.7723e-03,  2.4215e-02,\n",
      "          2.6313e-02, -1.1992e-02,  2.4418e-02, -2.2037e-02,  3.2757e-02,\n",
      "          8.8498e-03, -4.0825e-02, -3.3939e-02, -2.3449e-02, -5.1201e-02,\n",
      "         -7.4815e-02, -3.5578e-02,  3.4369e-03,  2.1197e-02,  3.0068e-02,\n",
      "         -2.0006e-02, -1.5689e-02, -2.8495e-02, -2.1130e-02, -8.1331e-03,\n",
      "         -1.7832e-02, -3.7484e-02, -4.2426e-03, -3.3006e-02,  6.8058e-03,\n",
      "         -3.3186e-02, -3.7548e-03, -2.7529e-02, -7.7572e-03, -9.6648e-03,\n",
      "          6.9789e-04, -1.1277e-02, -2.1338e-02,  3.2620e-02,  2.9197e-02,\n",
      "         -1.4650e-03, -4.8058e-03,  1.6026e-02,  1.0593e-02,  3.2075e-02,\n",
      "          6.1565e-02,  4.0318e-02,  5.9232e-02, -1.6977e-02, -3.1782e-02,\n",
      "          1.0494e-02, -2.8314e-03, -1.6597e-02, -1.1988e-02, -2.4696e-02,\n",
      "         -5.8477e-03, -2.2475e-02,  2.4981e-02, -1.3032e-02, -3.2997e-02,\n",
      "         -1.0204e-02,  3.0920e-02, -1.8513e-02, -3.2323e-02,  1.3523e-02,\n",
      "         -2.6144e-02, -3.1054e-02, -2.5040e-02,  3.6243e-02,  2.1369e-02,\n",
      "          8.7843e-03,  5.1717e-02,  1.0979e-01,  6.9349e-02,  8.5530e-02,\n",
      "          1.2468e-01,  7.8257e-02,  7.8776e-02,  3.5655e-02,  2.9504e-02,\n",
      "         -1.3174e-02,  5.2121e-03, -2.0436e-03, -2.6939e-02,  4.0989e-03,\n",
      "          3.1562e-02, -2.8521e-02,  3.1079e-02,  3.3447e-03, -2.0411e-02,\n",
      "         -2.3185e-02, -9.1086e-03,  2.4172e-02, -1.1418e-02,  3.2732e-02,\n",
      "          4.1546e-02,  3.6146e-02,  1.5585e-02,  4.6635e-02,  4.2084e-02,\n",
      "          1.2521e-01,  1.2205e-01,  8.0807e-02,  1.1433e-01,  9.9124e-02,\n",
      "          7.5128e-02,  2.1390e-02,  2.6880e-02,  1.7649e-02,  3.5977e-03,\n",
      "          2.9056e-02,  3.0007e-02, -2.1800e-02, -1.4164e-02,  2.7889e-02,\n",
      "          2.4921e-02, -2.1345e-02, -1.9131e-02,  2.2352e-02, -1.3808e-02,\n",
      "          2.8538e-02, -1.7031e-02,  2.7386e-02,  3.3468e-03,  1.3995e-02,\n",
      "         -2.2407e-02,  3.9256e-02, -4.9032e-03,  2.7986e-02,  7.3828e-02,\n",
      "          2.1417e-02,  4.6121e-02,  1.3065e-02,  2.3497e-02,  3.5521e-02,\n",
      "          4.0644e-02, -2.1723e-02, -8.8423e-03,  3.2669e-02, -5.6851e-03,\n",
      "         -3.4272e-03, -2.9115e-02,  2.8937e-02,  2.9867e-02,  4.6506e-03,\n",
      "         -7.3431e-03, -2.4374e-02, -1.0554e-02, -9.6395e-03, -2.0194e-02,\n",
      "          1.9687e-02,  2.0955e-02, -1.9953e-02, -1.9361e-02,  1.3506e-02,\n",
      "          1.8078e-03, -1.7127e-02,  6.1793e-03,  6.8617e-03,  2.8796e-02,\n",
      "         -5.6706e-03, -1.8549e-02,  2.3096e-02,  5.1317e-03, -9.0319e-03,\n",
      "         -1.7106e-02,  1.9787e-02,  5.2706e-03,  1.8099e-02, -2.2495e-02,\n",
      "         -2.0881e-02,  2.0506e-02,  2.0427e-02, -2.3320e-02]],\n",
      "       requires_grad=True)), ('fc.bias', Parameter containing:\n",
      "tensor([-0.0558], requires_grad=True)))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'view'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[351], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m_loss_grad_loader_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[350], line 5\u001b[0m, in \u001b[0;36m_loss_grad_loader_wrapper\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      3\u001b[0m params \u001b[38;5;241m=\u001b[39m _model_params(model)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(params)\n\u001b[0;32m----> 5\u001b[0m flat_params \u001b[38;5;241m=\u001b[39m \u001b[43m_flatten_params_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m flat_params\n",
      "Cell \u001b[0;32mIn[343], line 41\u001b[0m, in \u001b[0;36m_flatten_params_like\u001b[0;34m(params_like)\u001b[0m\n\u001b[1;32m     39\u001b[0m vec \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params_like:\n\u001b[0;32m---> 41\u001b[0m     vec\u001b[38;5;241m.\u001b[39mappend(\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(vec)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'view'"
     ]
    }
   ],
   "source": [
    "_loss_grad_loader_wrapper(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab06d37-31b6-44a4-9fca-0b0c65ac4bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "fbdf3afe-db09-4f23-a6e4-a1526988ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "mnist_train = datasets.MNIST(root=\"./data\", train=True, \n",
    "                             download=True, transform=transform)\n",
    "images, labels = mnist_train.data, mnist_train.targets\n",
    "\n",
    "# mnist_train_7 = torch.utils.data.Subset(mnist_train, indices=torch.where(labels==7)[0])\n",
    "mnist_train_7 = torch.utils.data.Subset(mnist_train, indices=[0,1,2,3,4])\n",
    "mnist_train_7 = torch.utils.data.DataLoader(mnist_train_7, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "9f7883cc-5080-48ab-b1db-58ef13014120",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[363], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmnist_train_7\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "mnist_train_7.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "da022fc3-93fd-4e2e-a537-7d835474c9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "for x, y in mnist_train_7:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "1d515b31-5cb2-4eb7-82a3-ba11bef4e888",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Subset' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[367], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmnist_train_7\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Subset' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "mnist_train_7.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "daf03070-0dc8-46e1-86e5-b53663058bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2087,  0.7829, -0.4156, -0.0695])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 3, 1])"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(4)\n",
    "print(a)\n",
    "\n",
    "torch.argsort(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc7ce44-9db7-4ea6-ac5a-a3653e4662a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
